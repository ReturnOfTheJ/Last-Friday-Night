{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from konlpy.tag import Komoran\n",
    "from konlpy.tag import Twitter\n",
    "from time import time\n",
    "import pickle\n",
    "import os\n",
    "import re\n",
    "from collections import Counter\n",
    "import collections\n",
    "import nltk\n",
    "import ast\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('konlpy mecab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\Anaconda3\\lib\\site-packages\\jpype\\_core.py:210: UserWarning: \n",
      "-------------------------------------------------------------------------------\n",
      "Deprecated: convertStrings was not specified when starting the JVM. The default\n",
      "behavior in JPype will be False starting in JPype 0.8. The recommended setting\n",
      "for new code is convertStrings=False.  The legacy value of True was assumed for\n",
      "this session. If you are a user of an application that reported this warning,\n",
      "please file a ticket with the developer.\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "  \"\"\")\n"
     ]
    }
   ],
   "source": [
    "from konlpy.tag import Okt\n",
    "okt = Okt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('raw.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0=df[0:50000]\n",
    "df1=df[50000:100000]\n",
    "df2=df[100000:150000]\n",
    "df3=df[150000:200000]\n",
    "df4=df[200000:250000]\n",
    "df5=df[250000:300000]\n",
    "df6=df[300000:350000]\n",
    "df7=df[350000:400000]\n",
    "df8=df[400000:450000]\n",
    "df9=df[450000:500000]\n",
    "df10=df[500000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 6922: expected 10 fields, saw 22\\n'\n",
      "b'Skipping line 26115: expected 10 fields, saw 22\\n'\n",
      "b'Skipping line 24557: expected 10 fields, saw 22\\nSkipping line 26317: expected 10 fields, saw 94\\n'\n",
      "b'Skipping line 66419: expected 10 fields, saw 22\\n'\n",
      "b'Skipping line 1890: expected 10 fields, saw 22\\nSkipping line 2116: expected 10 fields, saw 22\\nSkipping line 3203: expected 10 fields, saw 22\\nSkipping line 4407: expected 10 fields, saw 46\\nSkipping line 4808: expected 10 fields, saw 22\\nSkipping line 5085: expected 10 fields, saw 22\\nSkipping line 5196: expected 10 fields, saw 22\\nSkipping line 5408: expected 10 fields, saw 22\\nSkipping line 5765: expected 10 fields, saw 22\\nSkipping line 6098: expected 10 fields, saw 22\\nSkipping line 6532: expected 10 fields, saw 22\\nSkipping line 6703: expected 10 fields, saw 22\\nSkipping line 6862: expected 10 fields, saw 22\\nSkipping line 7396: expected 10 fields, saw 22\\nSkipping line 7613: expected 10 fields, saw 46\\nSkipping line 8083: expected 10 fields, saw 22\\nSkipping line 8357: expected 10 fields, saw 46\\nSkipping line 8980: expected 10 fields, saw 22\\nSkipping line 9350: expected 10 fields, saw 22\\nSkipping line 10738: expected 10 fields, saw 22\\nSkipping line 11759: expected 10 fields, saw 22\\nSkipping line 11813: expected 10 fields, saw 22\\nSkipping line 11853: expected 10 fields, saw 22\\nSkipping line 12326: expected 10 fields, saw 22\\nSkipping line 12450: expected 10 fields, saw 22\\nSkipping line 12555: expected 10 fields, saw 22\\nSkipping line 13432: expected 10 fields, saw 22\\nSkipping line 14249: expected 10 fields, saw 46\\nSkipping line 14430: expected 10 fields, saw 22\\nSkipping line 15107: expected 10 fields, saw 22\\nSkipping line 16651: expected 10 fields, saw 22\\nSkipping line 17053: expected 10 fields, saw 22\\nSkipping line 17958: expected 10 fields, saw 22\\nSkipping line 18391: expected 10 fields, saw 22\\nSkipping line 21407: expected 10 fields, saw 22\\nSkipping line 22911: expected 10 fields, saw 22\\nSkipping line 23612: expected 10 fields, saw 22\\nSkipping line 24072: expected 10 fields, saw 22\\nSkipping line 24410: expected 10 fields, saw 22\\nSkipping line 24950: expected 10 fields, saw 22\\nSkipping line 24962: expected 10 fields, saw 22\\nSkipping line 25872: expected 10 fields, saw 22\\nSkipping line 27219: expected 10 fields, saw 22\\nSkipping line 27442: expected 10 fields, saw 22\\nSkipping line 27766: expected 10 fields, saw 22\\nSkipping line 28155: expected 10 fields, saw 22\\nSkipping line 28481: expected 10 fields, saw 22\\nSkipping line 28627: expected 10 fields, saw 22\\nSkipping line 30173: expected 10 fields, saw 22\\nSkipping line 30545: expected 10 fields, saw 46\\nSkipping line 30685: expected 10 fields, saw 22\\nSkipping line 31619: expected 10 fields, saw 22\\nSkipping line 31888: expected 10 fields, saw 22\\nSkipping line 32001: expected 10 fields, saw 46\\nSkipping line 32478: expected 10 fields, saw 22\\nSkipping line 32876: expected 10 fields, saw 22\\nSkipping line 33938: expected 10 fields, saw 22\\nSkipping line 33940: expected 10 fields, saw 22\\nSkipping line 34331: expected 10 fields, saw 22\\nSkipping line 36045: expected 10 fields, saw 22\\nSkipping line 37043: expected 10 fields, saw 22\\nSkipping line 37075: expected 10 fields, saw 46\\nSkipping line 37126: expected 10 fields, saw 22\\nSkipping line 37693: expected 10 fields, saw 22\\nSkipping line 42569: expected 10 fields, saw 22\\nSkipping line 45297: expected 10 fields, saw 46\\nSkipping line 46490: expected 10 fields, saw 22\\nSkipping line 52498: expected 10 fields, saw 22\\nSkipping line 54158: expected 10 fields, saw 22\\nSkipping line 59199: expected 10 fields, saw 22\\nSkipping line 59243: expected 10 fields, saw 22\\nSkipping line 61320: expected 10 fields, saw 22\\nSkipping line 64226: expected 10 fields, saw 22\\n'\n",
      "b'Skipping line 74202: expected 10 fields, saw 22\\nSkipping line 76024: expected 10 fields, saw 22\\n'\n",
      "b'Skipping line 1725: expected 10 fields, saw 22\\nSkipping line 1762: expected 10 fields, saw 22\\nSkipping line 1943: expected 10 fields, saw 22\\nSkipping line 1948: expected 10 fields, saw 22\\nSkipping line 2172: expected 10 fields, saw 22\\nSkipping line 2395: expected 10 fields, saw 22\\nSkipping line 2518: expected 10 fields, saw 22\\nSkipping line 4400: expected 10 fields, saw 22\\nSkipping line 4559: expected 10 fields, saw 22\\nSkipping line 4716: expected 10 fields, saw 22\\nSkipping line 4907: expected 10 fields, saw 46\\nSkipping line 5025: expected 10 fields, saw 22\\nSkipping line 6342: expected 10 fields, saw 46\\nSkipping line 7092: expected 10 fields, saw 22\\nSkipping line 7170: expected 10 fields, saw 22\\nSkipping line 8025: expected 10 fields, saw 22\\nSkipping line 9500: expected 10 fields, saw 22\\nSkipping line 9609: expected 10 fields, saw 22\\nSkipping line 10701: expected 10 fields, saw 22\\nSkipping line 10814: expected 10 fields, saw 22\\nSkipping line 11275: expected 10 fields, saw 22\\nSkipping line 11662: expected 10 fields, saw 22\\nSkipping line 11864: expected 10 fields, saw 22\\nSkipping line 11968: expected 10 fields, saw 46\\nSkipping line 13971: expected 10 fields, saw 22\\nSkipping line 14157: expected 10 fields, saw 46\\nSkipping line 15932: expected 10 fields, saw 22\\nSkipping line 16192: expected 10 fields, saw 22\\nSkipping line 16491: expected 10 fields, saw 22\\nSkipping line 18503: expected 10 fields, saw 22\\nSkipping line 19724: expected 10 fields, saw 22\\nSkipping line 19727: expected 10 fields, saw 22\\nSkipping line 19848: expected 10 fields, saw 22\\nSkipping line 20142: expected 10 fields, saw 22\\nSkipping line 21564: expected 10 fields, saw 22\\nSkipping line 23064: expected 10 fields, saw 46\\nSkipping line 24051: expected 10 fields, saw 22\\nSkipping line 24826: expected 10 fields, saw 22\\nSkipping line 25534: expected 10 fields, saw 46\\nSkipping line 25630: expected 10 fields, saw 22\\nSkipping line 26011: expected 10 fields, saw 22\\nSkipping line 26026: expected 10 fields, saw 22\\nSkipping line 26268: expected 10 fields, saw 22\\nSkipping line 26454: expected 10 fields, saw 22\\nSkipping line 26501: expected 10 fields, saw 22\\nSkipping line 27722: expected 10 fields, saw 46\\nSkipping line 27991: expected 10 fields, saw 22\\nSkipping line 28001: expected 10 fields, saw 22\\nSkipping line 28168: expected 10 fields, saw 22\\nSkipping line 28247: expected 10 fields, saw 22\\nSkipping line 28444: expected 10 fields, saw 22\\nSkipping line 29259: expected 10 fields, saw 22\\nSkipping line 29275: expected 10 fields, saw 46\\nSkipping line 30257: expected 10 fields, saw 22\\nSkipping line 30375: expected 10 fields, saw 22\\nSkipping line 30584: expected 10 fields, saw 22\\nSkipping line 30848: expected 10 fields, saw 22\\nSkipping line 31791: expected 10 fields, saw 22\\nSkipping line 33280: expected 10 fields, saw 46\\nSkipping line 33291: expected 10 fields, saw 46\\nSkipping line 33921: expected 10 fields, saw 22\\nSkipping line 34029: expected 10 fields, saw 22\\nSkipping line 34132: expected 10 fields, saw 22\\nSkipping line 36596: expected 10 fields, saw 22\\nSkipping line 36752: expected 10 fields, saw 22\\nSkipping line 38647: expected 10 fields, saw 22\\nSkipping line 38885: expected 10 fields, saw 22\\nSkipping line 39063: expected 10 fields, saw 22\\nSkipping line 39452: expected 10 fields, saw 22\\nSkipping line 40410: expected 10 fields, saw 22\\nSkipping line 40562: expected 10 fields, saw 22\\nSkipping line 41091: expected 10 fields, saw 22\\nSkipping line 41153: expected 10 fields, saw 46\\nSkipping line 42039: expected 10 fields, saw 22\\nSkipping line 42913: expected 10 fields, saw 22\\nSkipping line 43419: expected 10 fields, saw 22\\nSkipping line 43437: expected 10 fields, saw 22\\nSkipping line 43587: expected 10 fields, saw 22\\nSkipping line 43641: expected 10 fields, saw 22\\nSkipping line 43981: expected 10 fields, saw 22\\nSkipping line 44317: expected 10 fields, saw 22\\nSkipping line 44441: expected 10 fields, saw 22\\nSkipping line 45955: expected 10 fields, saw 22\\nSkipping line 46458: expected 10 fields, saw 46\\nSkipping line 46461: expected 10 fields, saw 22\\nSkipping line 46577: expected 10 fields, saw 22\\nSkipping line 46795: expected 10 fields, saw 22\\nSkipping line 47812: expected 10 fields, saw 22\\nSkipping line 47898: expected 10 fields, saw 46\\nSkipping line 48798: expected 10 fields, saw 22\\nSkipping line 49040: expected 10 fields, saw 22\\nSkipping line 49506: expected 10 fields, saw 22\\nSkipping line 51450: expected 10 fields, saw 22\\nSkipping line 51803: expected 10 fields, saw 22\\nSkipping line 52714: expected 10 fields, saw 46\\nSkipping line 52722: expected 10 fields, saw 22\\nSkipping line 53228: expected 10 fields, saw 22\\nSkipping line 53289: expected 10 fields, saw 22\\nSkipping line 53375: expected 10 fields, saw 22\\nSkipping line 53398: expected 10 fields, saw 22\\nSkipping line 53542: expected 10 fields, saw 22\\nSkipping line 53675: expected 10 fields, saw 46\\nSkipping line 56004: expected 10 fields, saw 22\\nSkipping line 56305: expected 10 fields, saw 22\\nSkipping line 56582: expected 10 fields, saw 22\\nSkipping line 56671: expected 10 fields, saw 22\\nSkipping line 57879: expected 10 fields, saw 22\\nSkipping line 59565: expected 10 fields, saw 22\\nSkipping line 60126: expected 10 fields, saw 22\\nSkipping line 60216: expected 10 fields, saw 22\\nSkipping line 60714: expected 10 fields, saw 22\\nSkipping line 61211: expected 10 fields, saw 22\\nSkipping line 61556: expected 10 fields, saw 22\\nSkipping line 61736: expected 10 fields, saw 22\\nSkipping line 61769: expected 10 fields, saw 22\\nSkipping line 61881: expected 10 fields, saw 22\\nSkipping line 63078: expected 10 fields, saw 22\\nSkipping line 63782: expected 10 fields, saw 22\\nSkipping line 64009: expected 10 fields, saw 22\\nSkipping line 64013: expected 10 fields, saw 22\\nSkipping line 64085: expected 10 fields, saw 22\\nSkipping line 64189: expected 10 fields, saw 22\\nSkipping line 64371: expected 10 fields, saw 46\\nSkipping line 64435: expected 10 fields, saw 22\\nSkipping line 64866: expected 10 fields, saw 22\\n'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 67573: expected 10 fields, saw 46\\nSkipping line 68414: expected 10 fields, saw 22\\nSkipping line 68717: expected 10 fields, saw 46\\nSkipping line 68829: expected 10 fields, saw 22\\nSkipping line 68907: expected 10 fields, saw 22\\nSkipping line 68948: expected 10 fields, saw 22\\nSkipping line 69336: expected 10 fields, saw 46\\nSkipping line 69343: expected 10 fields, saw 46\\nSkipping line 69348: expected 10 fields, saw 22\\nSkipping line 69361: expected 10 fields, saw 22\\nSkipping line 69525: expected 10 fields, saw 46\\nSkipping line 69553: expected 10 fields, saw 22\\nSkipping line 69591: expected 10 fields, saw 22\\nSkipping line 69615: expected 10 fields, saw 22\\nSkipping line 69690: expected 10 fields, saw 46\\nSkipping line 69769: expected 10 fields, saw 22\\nSkipping line 70602: expected 10 fields, saw 22\\nSkipping line 72792: expected 10 fields, saw 22\\nSkipping line 72992: expected 10 fields, saw 22\\nSkipping line 73021: expected 10 fields, saw 22\\nSkipping line 73077: expected 10 fields, saw 22\\nSkipping line 75178: expected 10 fields, saw 22\\nSkipping line 75407: expected 10 fields, saw 22\\nSkipping line 75524: expected 10 fields, saw 22\\nSkipping line 75533: expected 10 fields, saw 22\\nSkipping line 76283: expected 10 fields, saw 22\\nSkipping line 76504: expected 10 fields, saw 22\\nSkipping line 77353: expected 10 fields, saw 46\\nSkipping line 77392: expected 10 fields, saw 22\\nSkipping line 77984: expected 10 fields, saw 22\\nSkipping line 78175: expected 10 fields, saw 22\\nSkipping line 78233: expected 10 fields, saw 22\\nSkipping line 78565: expected 10 fields, saw 22\\nSkipping line 78600: expected 10 fields, saw 22\\n'\n",
      "b'Skipping line 756: expected 10 fields, saw 46\\nSkipping line 2560: expected 10 fields, saw 22\\nSkipping line 3488: expected 10 fields, saw 22\\nSkipping line 3673: expected 10 fields, saw 22\\nSkipping line 4135: expected 10 fields, saw 22\\nSkipping line 4307: expected 10 fields, saw 22\\nSkipping line 6013: expected 10 fields, saw 22\\nSkipping line 7676: expected 10 fields, saw 22\\nSkipping line 8157: expected 10 fields, saw 22\\nSkipping line 8545: expected 10 fields, saw 22\\nSkipping line 9213: expected 10 fields, saw 22\\nSkipping line 10362: expected 10 fields, saw 22\\nSkipping line 10463: expected 10 fields, saw 22\\nSkipping line 11572: expected 10 fields, saw 22\\nSkipping line 11608: expected 10 fields, saw 22\\nSkipping line 13342: expected 10 fields, saw 22\\nSkipping line 13487: expected 10 fields, saw 22\\nSkipping line 14992: expected 10 fields, saw 22\\nSkipping line 15159: expected 10 fields, saw 46\\nSkipping line 16124: expected 10 fields, saw 46\\nSkipping line 16220: expected 10 fields, saw 46\\nSkipping line 16623: expected 10 fields, saw 22\\nSkipping line 16702: expected 10 fields, saw 22\\nSkipping line 16930: expected 10 fields, saw 46\\nSkipping line 17299: expected 10 fields, saw 22\\nSkipping line 17883: expected 10 fields, saw 22\\nSkipping line 18369: expected 10 fields, saw 46\\nSkipping line 18576: expected 10 fields, saw 22\\nSkipping line 19068: expected 10 fields, saw 22\\nSkipping line 19208: expected 10 fields, saw 22\\nSkipping line 19295: expected 10 fields, saw 22\\nSkipping line 19604: expected 10 fields, saw 22\\n'\n"
     ]
    }
   ],
   "source": [
    "dfy0=pd.read_csv('0.csv', error_bad_lines=False)['Overall']\n",
    "dfy1=pd.read_csv('1.csv', error_bad_lines=False)['Overall']\n",
    "dfy2=pd.read_csv('2.csv', error_bad_lines=False)['Overall']\n",
    "dfy3=pd.read_csv('3.csv', error_bad_lines=False)['Overall']\n",
    "dfy4=pd.read_csv('4.csv', error_bad_lines=False)['Overall']\n",
    "dfy5=pd.read_csv('5.csv', error_bad_lines=False)['Overall']\n",
    "dfy6=pd.read_csv('6.csv', error_bad_lines=False)['Overall']\n",
    "dfy7=pd.read_csv('7.csv', error_bad_lines=False)['Overall']\n",
    "dfy8=pd.read_csv('8.csv', error_bad_lines=False)['Overall']\n",
    "dfy9=pd.read_csv('9.csv', error_bad_lines=False)['Overall']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfy = pd.concat([dfy0,dfy1,dfy2,dfy3,dfy4,dfy5,dfy6,dfy7,dfy8,dfy9], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfyy0=dfy[0:50000]\n",
    "dfyy1=dfy[50000:100000]\n",
    "dfyy2=dfy[100000:150000]\n",
    "dfyy3=dfy[150000:200000]\n",
    "dfyy4=dfy[200000:250000]\n",
    "dfyy5=dfy[250000:300000]\n",
    "dfyy6=dfy[300000:350000]\n",
    "dfyy7=dfy[350000:400000]\n",
    "dfyy8=dfy[400000:450000]\n",
    "dfyy9=dfy[450000:500000]\n",
    "dfyy10=dfy[500000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfyy = pd.concat([dfyy0,dfyy1,dfyy2,dfyy3,dfyy4,dfyy5,dfyy6,dfyy7,dfyy8,dfyy9, dfyy10], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfyyy=dfyy.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray, 526154, (526154,))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dfyyy), len(dfyyy), dfyyy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tokenizer(column):\n",
    "    return okt.morphs(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df0['Comment']=df0['Comment'].apply(get_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df1['Comment']=df1['Comment'].apply(get_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df2['Comment']=df2['Comment'].apply(get_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df3['Comment']=df3['Comment'].apply(get_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df4['Comment']=df4['Comment'].apply(get_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "C:\\Users\\admin\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "df5['Comment']=df5['Comment'].apply(get_tokenizer)\n",
    "df6['Comment']=df6['Comment'].apply(get_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "C:\\Users\\admin\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "df7['Comment']=df7['Comment'].apply(get_tokenizer)\n",
    "df8['Comment']=df8['Comment'].apply(get_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "C:\\Users\\admin\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "df9['Comment']=df9['Comment'].apply(get_tokenizer)\n",
    "df10['Comment']=df10['Comment'].apply(get_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfx = pd.concat([df0,df1,df2,df3,df4,df5,df6,df7,df8,df9,df10], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = [t for d in dfx['Comment'] for t in d]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "c=Counter(tokens)\n",
    "c.most_common(30000)\n",
    "a=c.most_common(30000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_token=dict(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30000"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab=sorted(most_token, key=most_token.get, reverse=True)\n",
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2idx = {word.encode('utf8').decode('utf8'): ii for ii, word in enumerate(vocab,1)}\n",
    "word2idx = {k:v+3 for k, v in word2idx.items()}\n",
    "word2idx['<PAD>'] = 0\n",
    "word2idx['<START>'] = 1\n",
    "word2idx['<UNK>'] = 2\n",
    "word2idx['<UNUSED>'] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'.': 4,\n",
       " '이': 5,\n",
       " '에': 6,\n",
       " '을': 7,\n",
       " '수업': 8,\n",
       " '은': 9,\n",
       " ',': 10,\n",
       " '님': 11,\n",
       " '교수': 12,\n",
       " '도': 13,\n",
       " '는': 14,\n",
       " '를': 15,\n",
       " '시험': 16,\n",
       " '가': 17,\n",
       " '\\n': 18,\n",
       " '것': 19,\n",
       " '잘': 20,\n",
       " '강의': 21,\n",
       " '들': 22,\n",
       " '의': 23,\n",
       " '으로': 24,\n",
       " '내용': 25,\n",
       " '수': 26,\n",
       " '로': 27,\n",
       " '한': 28,\n",
       " '문제': 29,\n",
       " '과제': 30,\n",
       " '학점': 31,\n",
       " '적': 32,\n",
       " '말': 33,\n",
       " '다': 34,\n",
       " '입니다': 35,\n",
       " '중간': 36,\n",
       " '만': 37,\n",
       " '출석': 38,\n",
       " '공부': 39,\n",
       " '안': 40,\n",
       " '하는': 41,\n",
       " '기': 42,\n",
       " '시간': 43,\n",
       " '많이': 44,\n",
       " '합니다': 45,\n",
       " '정말': 46,\n",
       " '때': 47,\n",
       " '생각': 48,\n",
       " '학생': 49,\n",
       " '하고': 50,\n",
       " '에서': 51,\n",
       " '과': 52,\n",
       " '할': 53,\n",
       " '발표': 54,\n",
       " '정도': 55,\n",
       " '\\n\\n': 56,\n",
       " '열심히': 57,\n",
       " '있습니다': 58,\n",
       " '때문': 59,\n",
       " '하면': 60,\n",
       " '번': 61,\n",
       " '고': 62,\n",
       " '같습니다': 63,\n",
       " '학기': 64,\n",
       " '..': 65,\n",
       " '점수': 66,\n",
       " '인': 67,\n",
       " '!': 68,\n",
       " '...': 69,\n",
       " '있는': 70,\n",
       " '중간고사': 71,\n",
       " '성적': 72,\n",
       " '체크': 73,\n",
       " '해서': 74,\n",
       " '기말고사': 75,\n",
       " '좀': 76,\n",
       " '설명': 77,\n",
       " '좋은': 78,\n",
       " '너무': 79,\n",
       " '께서': 80,\n",
       " '책': 81,\n",
       " '진행': 82,\n",
       " '그': 83,\n",
       " '됩니다': 84,\n",
       " '와': 85,\n",
       " '그냥': 86,\n",
       " '과목': 87,\n",
       " '1': 88,\n",
       " '하지만': 89,\n",
       " '분': 90,\n",
       " '거의': 91,\n",
       " '매우': 92,\n",
       " '2': 93,\n",
       " '형': 94,\n",
       " '저': 95,\n",
       " '조금': 96,\n",
       " '에는': 97,\n",
       " '하나': 98,\n",
       " '대해': 99,\n",
       " '못': 100,\n",
       " '서': 101,\n",
       " '중': 102,\n",
       " '이해': 103,\n",
       " '부분': 104,\n",
       " '그리고': 105,\n",
       " '추천': 106,\n",
       " '거': 107,\n",
       " '게': 108,\n",
       " '전': 109,\n",
       " '같아요': 110,\n",
       " '(': 111,\n",
       " '식': 112,\n",
       " '점': 113,\n",
       " '팀': 114,\n",
       " '영어': 115,\n",
       " '많은': 116,\n",
       " '하시는': 117,\n",
       " '+': 118,\n",
       " '해': 119,\n",
       " '레포트': 120,\n",
       " '주시': 121,\n",
       " '하시고': 122,\n",
       " '서술': 123,\n",
       " ')': 124,\n",
       " '요': 125,\n",
       " '사람': 126,\n",
       " '한번': 127,\n",
       " '필기': 128,\n",
       " '퀴즈': 129,\n",
       " '교재': 130,\n",
       " '다른': 131,\n",
       " '하십니다': 132,\n",
       " '대한': 133,\n",
       " '나': 134,\n",
       " '출첵': 135,\n",
       " '굉장히': 136,\n",
       " '3': 137,\n",
       " '자체': 138,\n",
       " '부담': 139,\n",
       " '력': 140,\n",
       " '보다': 141,\n",
       " '그래도': 142,\n",
       " '인데': 143,\n",
       " '이라': 144,\n",
       " '해야': 145,\n",
       " '면': 146,\n",
       " 'A': 147,\n",
       " '두': 148,\n",
       " '개': 149,\n",
       " '평가': 150,\n",
       " '난이도': 151,\n",
       " '더': 152,\n",
       " '진짜': 153,\n",
       " '없고': 154,\n",
       " '개인': 155,\n",
       " '하': 156,\n",
       " '별로': 157,\n",
       " '다만': 158,\n",
       " '까지': 159,\n",
       " '않습니다': 160,\n",
       " '하기': 161,\n",
       " '있고': 162,\n",
       " '편이': 163,\n",
       " '제': 164,\n",
       " '어렵지': 165,\n",
       " '보고': 166,\n",
       " '처음': 167,\n",
       " '제출': 168,\n",
       " '보면': 169,\n",
       " '있는데': 170,\n",
       " '질문': 171,\n",
       " '되는': 172,\n",
       " '준비': 173,\n",
       " '플': 174,\n",
       " '모두': 175,\n",
       " '피피티': 176,\n",
       " '하지': 177,\n",
       " '않고': 178,\n",
       " '이고': 179,\n",
       " '니': 180,\n",
       " '쉽게': 181,\n",
       " '답': 182,\n",
       " '하게': 183,\n",
       " '큰': 184,\n",
       " '주제': 185,\n",
       " '하는데': 186,\n",
       " '말씀': 187,\n",
       " '팀플': 188,\n",
       " '무난': 189,\n",
       " '씩': 190,\n",
       " '자료': 191,\n",
       " '범위': 192,\n",
       " '내': 193,\n",
       " '듣고': 194,\n",
       " '이번': 195,\n",
       " '하시면': 196,\n",
       " '없습니다': 197,\n",
       " '이나': 198,\n",
       " '라': 199,\n",
       " 'ppt': 200,\n",
       " '듯': 201,\n",
       " '같은': 202,\n",
       " '경우': 203,\n",
       " '이었습니다': 204,\n",
       " '편': 205,\n",
       " '배우는': 206,\n",
       " '없는': 207,\n",
       " '걸': 208,\n",
       " '없이': 209,\n",
       " '조': 210,\n",
       " '관련': 211,\n",
       " '토론': 212,\n",
       " '엄청': 213,\n",
       " '받을': 214,\n",
       " '방식': 215,\n",
       " '나옵니다': 216,\n",
       " '하셔서': 217,\n",
       " '크게': 218,\n",
       " '지': 219,\n",
       " '근데': 220,\n",
       " '어려운': 221,\n",
       " '4': 222,\n",
       " '매': 223,\n",
       " '그렇게': 224,\n",
       " '등': 225,\n",
       " '알': 226,\n",
       " '마다': 227,\n",
       " '양': 228,\n",
       " '?': 229,\n",
       " '매일': 230,\n",
       " '관심': 231,\n",
       " '주십니다': 232,\n",
       " \"'\": 233,\n",
       " '꽤': 234,\n",
       " '된': 235,\n",
       " '항상': 236,\n",
       " '대체': 237,\n",
       " '느낌': 238,\n",
       " '위주': 239,\n",
       " '객관': 240,\n",
       " '학': 241,\n",
       " '있어요': 242,\n",
       " '집중': 243,\n",
       " '일단': 244,\n",
       " '만큼': 245,\n",
       " '꼭': 246,\n",
       " '미리': 247,\n",
       " '도움': 248,\n",
       " '들을': 249,\n",
       " '이다': 250,\n",
       " '가끔': 251,\n",
       " '명': 252,\n",
       " '사실': 253,\n",
       " '있어서': 254,\n",
       " '~': 255,\n",
       " '많고': 256,\n",
       " 'ㅠㅠ': 257,\n",
       " '했는데': 258,\n",
       " '좋습니다': 259,\n",
       " ':': 260,\n",
       " '라고': 261,\n",
       " '많아서': 262,\n",
       " '배운': 263,\n",
       " '에게': 264,\n",
       " '후': 265,\n",
       " '따로': 266,\n",
       " '나오는': 267,\n",
       " '습량': 268,\n",
       " '별': 269,\n",
       " '단': 270,\n",
       " '주': 271,\n",
       " '듣는': 272,\n",
       " '될': 273,\n",
       " '였습니다': 274,\n",
       " '있을': 275,\n",
       " '해도': 276,\n",
       " '전반': 277,\n",
       " '교양': 278,\n",
       " '들으면': 279,\n",
       " '출제': 280,\n",
       " '동안': 281,\n",
       " '노력': 282,\n",
       " '참여': 283,\n",
       " '그래서': 284,\n",
       " '매주': 285,\n",
       " '이라고': 286,\n",
       " '가장': 287,\n",
       " '보니': 288,\n",
       " '볼': 289,\n",
       " '성취': 290,\n",
       " '랑': 291,\n",
       " '기간': 292,\n",
       " '....': 293,\n",
       " '수준': 294,\n",
       " '들어': 295,\n",
       " '5': 296,\n",
       " '연습': 297,\n",
       " '했습니다': 298,\n",
       " '가지': 299,\n",
       " '부터': 300,\n",
       " '정리': 301,\n",
       " '편입': 302,\n",
       " '많습니다': 303,\n",
       " '자신': 304,\n",
       " '보다는': 305,\n",
       " '지식': 306,\n",
       " '하시는데': 307,\n",
       " '영강': 308,\n",
       " '개념': 309,\n",
       " '쓰는': 310,\n",
       " '조교': 311,\n",
       " '약간': 312,\n",
       " '좋았습니다': 313,\n",
       " '있었습니다': 314,\n",
       " '매번': 315,\n",
       " '있지만': 316,\n",
       " '감': 317,\n",
       " '!!': 318,\n",
       " '나름': 319,\n",
       " '해주십니다': 320,\n",
       " '이지만': 321,\n",
       " '진도': 322,\n",
       " 'ㅎㅎ': 323,\n",
       " '전체': 324,\n",
       " '듣기': 325,\n",
       " '/': 326,\n",
       " '시': 327,\n",
       " '같이': 328,\n",
       " '함': 329,\n",
       " '이랑': 330,\n",
       " '아주': 331,\n",
       " '에도': 332,\n",
       " '하신': 333,\n",
       " '이론': 334,\n",
       " '대부분': 335,\n",
       " '전공': 336,\n",
       " '읽고': 337,\n",
       " '수도': 338,\n",
       " '기본': 339,\n",
       " '하세요': 340,\n",
       " '작성': 341,\n",
       " '건': 342,\n",
       " '대신': 343,\n",
       " '배울': 344,\n",
       " '상당히': 345,\n",
       " '열정': 346,\n",
       " '않은': 347,\n",
       " '어느': 348,\n",
       " '아니라': 349,\n",
       " '라서': 350,\n",
       " '전혀': 351,\n",
       " '암기': 352,\n",
       " '보고서': 353,\n",
       " '형식': 354,\n",
       " '심': 355,\n",
       " '지만': 356,\n",
       " '모든': 357,\n",
       " '기준': 358,\n",
       " '이상': 359,\n",
       " '되고': 360,\n",
       " '일': 361,\n",
       " '데': 362,\n",
       " '또': 363,\n",
       " '영화': 364,\n",
       " '풀': 365,\n",
       " '겁니다': 366,\n",
       " '장': 367,\n",
       " '평소': 368,\n",
       " '-': 369,\n",
       " '시작': 370,\n",
       " '그대로': 371,\n",
       " '해주셔서': 372,\n",
       " '프린트': 373,\n",
       " '분량': 374,\n",
       " '역사': 375,\n",
       " '이에요': 376,\n",
       " '글': 377,\n",
       " '있다': 378,\n",
       " '좋아요': 379,\n",
       " '에요': 380,\n",
       " '마지막': 381,\n",
       " '문': 382,\n",
       " '이야기': 383,\n",
       " '중요한': 384,\n",
       " '아': 385,\n",
       " '이후': 386,\n",
       " '이름': 387,\n",
       " '기억': 388,\n",
       " '대': 389,\n",
       " '뭐': 390,\n",
       " '이런': 391,\n",
       " '생': 392,\n",
       " '본인': 393,\n",
       " '쉬운': 394,\n",
       " '여러': 395,\n",
       " '수강': 396,\n",
       " '상': 397,\n",
       " '몇': 398,\n",
       " '충분히': 399,\n",
       " '교시': 400,\n",
       " '10': 401,\n",
       " '하실': 402,\n",
       " '자주': 403,\n",
       " '그런데': 404,\n",
       " '임': 405,\n",
       " '라는': 406,\n",
       " '물론': 407,\n",
       " '해주시': 408,\n",
       " '라면': 409,\n",
       " '최고': 410,\n",
       " '총': 411,\n",
       " 'PPT': 412,\n",
       " '비중': 413,\n",
       " '직접': 414,\n",
       " '자기': 415,\n",
       " '엔': 416,\n",
       " '그런': 417,\n",
       " '약': 418,\n",
       " '무엇': 419,\n",
       " '실험': 420,\n",
       " '보는': 421,\n",
       " '보시': 422,\n",
       " '논문': 423,\n",
       " '있음': 424,\n",
       " '듣지': 425,\n",
       " '오픈': 426,\n",
       " '한다': 427,\n",
       " '복습': 428,\n",
       " '제대로': 429,\n",
       " '하여': 430,\n",
       " '한자': 431,\n",
       " '북': 432,\n",
       " '꿀강': 433,\n",
       " '반': 434,\n",
       " '같다': 435,\n",
       " '필요': 436,\n",
       " '특히': 437,\n",
       " '또한': 438,\n",
       " '에세이': 439,\n",
       " '단어': 440,\n",
       " '어떻게': 441,\n",
       " '딱': 442,\n",
       " '얘기': 443,\n",
       " '프로젝트': 444,\n",
       " '이라는': 445,\n",
       " '숙제': 446,\n",
       " '그런지': 447,\n",
       " '워낙': 448,\n",
       " '인지': 449,\n",
       " '이기': 450,\n",
       " '솔직히': 451,\n",
       " '나와서': 452,\n",
       " '않아요': 453,\n",
       " '랜덤': 454,\n",
       " '어떤': 455,\n",
       " '했던': 456,\n",
       " '같네요': 457,\n",
       " '지각': 458,\n",
       " '기초': 459,\n",
       " '그것': 460,\n",
       " '들은': 461,\n",
       " '혼자': 462,\n",
       " '주로': 463,\n",
       " '어렵습니다': 464,\n",
       " '주관': 465,\n",
       " '기출': 466,\n",
       " '앞': 467,\n",
       " '이쁠': 468,\n",
       " '그러나': 469,\n",
       " '한다면': 470,\n",
       " '않는': 471,\n",
       " '되게': 472,\n",
       " '어려움': 473,\n",
       " '다음': 474,\n",
       " '결석': 475,\n",
       " '평균': 476,\n",
       " '전부': 477,\n",
       " '했지만': 478,\n",
       " '대로': 479,\n",
       " '기도': 480,\n",
       " '하면서': 481,\n",
       " '없어서': 482,\n",
       " '봅니다': 483,\n",
       " '나중': 484,\n",
       " '참고': 485,\n",
       " '재밌게': 486,\n",
       " '그만큼': 487,\n",
       " '차': 488,\n",
       " '나오고': 489,\n",
       " '날': 490,\n",
       " '해주시고': 491,\n",
       " '다시': 492,\n",
       " '되는데': 493,\n",
       " '전달': 494,\n",
       " '에이': 495,\n",
       " '께': 496,\n",
       " '글쓰기': 497,\n",
       " '비해': 498,\n",
       " '의견': 499,\n",
       " '딱히': 500,\n",
       " '꿀': 501,\n",
       " '고등학교': 502,\n",
       " '빡세': 503,\n",
       " '선택': 504,\n",
       " '좋을': 505,\n",
       " '권': 506,\n",
       " '절대': 507,\n",
       " '법': 508,\n",
       " '줄': 509,\n",
       " '철학': 510,\n",
       " '완전': 511,\n",
       " '주심': 512,\n",
       " '본': 513,\n",
       " '학년': 514,\n",
       " '분들': 515,\n",
       " '분야': 516,\n",
       " '사용': 517,\n",
       " '요약': 518,\n",
       " '처럼': 519,\n",
       " '실제': 520,\n",
       " '목소리': 521,\n",
       " '까지는': 522,\n",
       " '통해': 523,\n",
       " '스타일': 524,\n",
       " '에서는': 525,\n",
       " '작품': 526,\n",
       " '흥미': 527,\n",
       " '수학': 528,\n",
       " '않지만': 529,\n",
       " '판서': 530,\n",
       " '좋으시고': 531,\n",
       " '이라서': 532,\n",
       " '다소': 533,\n",
       " '무조건': 534,\n",
       " '해석': 535,\n",
       " '내내': 536,\n",
       " '배우고': 537,\n",
       " '되어': 538,\n",
       " '걱정': 539,\n",
       " '많아요': 540,\n",
       " '교과서': 541,\n",
       " '비': 542,\n",
       " '각': 543,\n",
       " '계속': 544,\n",
       " '됨': 545,\n",
       " '꼼꼼히': 546,\n",
       " '있게': 547,\n",
       " '쪽': 548,\n",
       " '않아서': 549,\n",
       " '뒤': 550,\n",
       " '하는게': 551,\n",
       " 'B': 552,\n",
       " '하셔야': 553,\n",
       " '및': 554,\n",
       " '분석': 555,\n",
       " '흐름': 556,\n",
       " '공': 557,\n",
       " '같은데': 558,\n",
       " '달달': 559,\n",
       " '배려': 560,\n",
       " '술': 561,\n",
       " '왜': 562,\n",
       " '초반': 563,\n",
       " '없어요': 564,\n",
       " '결과': 565,\n",
       " '하다': 566,\n",
       " '으로는': 567,\n",
       " '같고': 568,\n",
       " '경제': 569,\n",
       " '반영': 570,\n",
       " '이렇게': 571,\n",
       " '있으면': 572,\n",
       " '않았습니다': 573,\n",
       " '최대한': 574,\n",
       " '따라': 575,\n",
       " '아닙니다': 576,\n",
       " '여서': 577,\n",
       " '보는데': 578,\n",
       " '참': 579,\n",
       " '관': 580,\n",
       " '친구': 581,\n",
       " '외우면': 582,\n",
       " '위': 583,\n",
       " '제일': 584,\n",
       " '나왔습니다': 585,\n",
       " '아닌': 586,\n",
       " '쉽고': 587,\n",
       " '주셔서': 588,\n",
       " '피드백': 589,\n",
       " '있다면': 590,\n",
       " '재미있게': 591,\n",
       " 'ㅠ': 592,\n",
       " '들으세요': 593,\n",
       " '해요': 594,\n",
       " '그리': 595,\n",
       " '다양한': 596,\n",
       " '많지': 597,\n",
       " '쓰면': 598,\n",
       " '실습': 599,\n",
       " '보통': 600,\n",
       " '대형': 601,\n",
       " '않게': 602,\n",
       " '들었던': 603,\n",
       " '가르쳐': 604,\n",
       " '만점': 605,\n",
       " '좋으신': 606,\n",
       " '된다': 607,\n",
       " '되지': 608,\n",
       " '강조': 609,\n",
       " '역시': 610,\n",
       " '않으면': 611,\n",
       " '나올': 612,\n",
       " '외': 613,\n",
       " '아니고': 614,\n",
       " '통계': 615,\n",
       " '하시기': 616,\n",
       " '들었습니다': 617,\n",
       " '아예': 618,\n",
       " '영상': 619,\n",
       " '경제학': 620,\n",
       " '끝나고': 621,\n",
       " '세': 622,\n",
       " '학우': 623,\n",
       " '밖에': 624,\n",
       " '대충': 625,\n",
       " '보기': 626,\n",
       " '자': 627,\n",
       " '받아': 628,\n",
       " '사회': 629,\n",
       " '원래': 630,\n",
       " '나오는데': 631,\n",
       " '나와요': 632,\n",
       " '마음': 633,\n",
       " '풀어': 634,\n",
       " '배웁니다': 635,\n",
       " '계산': 636,\n",
       " '끝': 637,\n",
       " '갈': 638,\n",
       " '실력': 639,\n",
       " '에게는': 640,\n",
       " '채점': 641,\n",
       " '높은': 642,\n",
       " '페이지': 643,\n",
       " '힘든': 644,\n",
       " '위해': 645,\n",
       " '없음': 646,\n",
       " '문과': 647,\n",
       " '니까': 648,\n",
       " '비교': 649,\n",
       " '한국': 650,\n",
       " '되었습니다': 651,\n",
       " '과정': 652,\n",
       " '우선': 653,\n",
       " 'ㅋㅋ': 654,\n",
       " '들어도': 655,\n",
       " '정': 656,\n",
       " '어렵지는': 657,\n",
       " '음': 658,\n",
       " '하루': 659,\n",
       " '한국어': 660,\n",
       " '절대평가': 661,\n",
       " '받았습니다': 662,\n",
       " '어렵고': 663,\n",
       " '한데': 664,\n",
       " '뭘': 665,\n",
       " '좋았어요': 666,\n",
       " '첫': 667,\n",
       " '히': 668,\n",
       " '하셨습니다': 669,\n",
       " '분위기': 670,\n",
       " '영향': 671,\n",
       " '싶은': 672,\n",
       " '자리': 673,\n",
       " '쯤': 674,\n",
       " 'a': 675,\n",
       " '학습': 676,\n",
       " '\"': 677,\n",
       " '비추': 678,\n",
       " '중요합니다': 679,\n",
       " '구': 680,\n",
       " '요구': 681,\n",
       " '친절하시고': 682,\n",
       " '뭔가': 683,\n",
       " '공부량': 684,\n",
       " '예상': 685,\n",
       " '한테': 686,\n",
       " '출': 687,\n",
       " '문학': 688,\n",
       " '하시지만': 689,\n",
       " '들었는데': 690,\n",
       " '편하게': 691,\n",
       " '쓰기': 692,\n",
       " '이어서': 693,\n",
       " '받으실': 694,\n",
       " '의미': 695,\n",
       " '답안': 696,\n",
       " '중심': 697,\n",
       " '필수': 698,\n",
       " '마세요': 699,\n",
       " '어렵게': 700,\n",
       " '일주일': 701,\n",
       " '시기': 702,\n",
       " '단점': 703,\n",
       " '없었습니다': 704,\n",
       " '주는': 705,\n",
       " '있었는데': 706,\n",
       " '방법': 707,\n",
       " '그거': 708,\n",
       " '무리': 709,\n",
       " '문화': 710,\n",
       " '없다': 711,\n",
       " '선생님': 712,\n",
       " '바탕': 713,\n",
       " '단원': 714,\n",
       " '많지만': 715,\n",
       " '여': 716,\n",
       " '수강생': 717,\n",
       " '쓸': 718,\n",
       " '체계': 719,\n",
       " '읽어': 720,\n",
       " '경': 721,\n",
       " '드립니다': 722,\n",
       " '끝날': 723,\n",
       " '투자': 724,\n",
       " '해주시는': 725,\n",
       " '뿐': 726,\n",
       " '좋고': 727,\n",
       " '영': 728,\n",
       " '6': 729,\n",
       " '있었던': 730,\n",
       " '발음': 731,\n",
       " '안해': 732,\n",
       " '용이': 733,\n",
       " '없을': 734,\n",
       " '구성': 735,\n",
       " '돼요': 736,\n",
       " '괜찮은': 737,\n",
       " '힘듭니다': 738,\n",
       " '불구': 739,\n",
       " '거기': 740,\n",
       " '블랙보드': 741,\n",
       " '없지만': 742,\n",
       " '논술': 743,\n",
       " '지는': 744,\n",
       " '힘들': 745,\n",
       " '좋으십니다': 746,\n",
       " '번역': 747,\n",
       " '써야': 748,\n",
       " '들어야': 749,\n",
       " '무슨': 750,\n",
       " '친절하게': 751,\n",
       " '정치': 752,\n",
       " '쉽습니다': 753,\n",
       " '있어': 754,\n",
       " '했어요': 755,\n",
       " '감은': 756,\n",
       " '언어': 757,\n",
       " '들으시면': 758,\n",
       " '터': 759,\n",
       " '스스로': 760,\n",
       " '특성': 761,\n",
       " '거나': 762,\n",
       " '간단한': 763,\n",
       " '성': 764,\n",
       " '번의': 765,\n",
       " '접': 766,\n",
       " '쓰고': 767,\n",
       " '네': 768,\n",
       " '신경': 769,\n",
       " '기회': 770,\n",
       " '아는': 771,\n",
       " '문법': 772,\n",
       " '얻을': 773,\n",
       " '재미': 774,\n",
       " '아무': 775,\n",
       " '적당히': 776,\n",
       " '강': 777,\n",
       " '꼼꼼하게': 778,\n",
       " '평': 779,\n",
       " '경험': 780,\n",
       " '있었고': 781,\n",
       " '주의': 782,\n",
       " '하며': 783,\n",
       " '많아': 784,\n",
       " '했고': 785,\n",
       " '나오기': 786,\n",
       " '원': 787,\n",
       " '다루는': 788,\n",
       " '사례': 789,\n",
       " '이었는데': 790,\n",
       " '어려울': 791,\n",
       " '활용': 792,\n",
       " '나온': 793,\n",
       " '20': 794,\n",
       " '받기': 795,\n",
       " '함께': 796,\n",
       " '포기': 797,\n",
       " '힘들었습니다': 798,\n",
       " '대학': 799,\n",
       " '가면': 800,\n",
       " 'ㅎ': 801,\n",
       " '수가': 802,\n",
       " '종이': 803,\n",
       " '나옴': 804,\n",
       " '확실히': 805,\n",
       " '지정': 806,\n",
       " '급': 807,\n",
       " '훨씬': 808,\n",
       " '재밌고': 809,\n",
       " '당황': 810,\n",
       " '짜리': 811,\n",
       " '써서': 812,\n",
       " '아니지만': 813,\n",
       " '손': 814,\n",
       " '갓': 815,\n",
       " '핵심': 816,\n",
       " '따라가기': 817,\n",
       " '소설': 818,\n",
       " '모르는': 819,\n",
       " 'ㅜㅜ': 820,\n",
       " '나머지': 821,\n",
       " '말로': 822,\n",
       " '결정': 823,\n",
       " '봐도': 824,\n",
       " '우리': 825,\n",
       " '재수강': 826,\n",
       " '한다고': 827,\n",
       " '바랍니다': 828,\n",
       " '전날': 829,\n",
       " '이었어요': 830,\n",
       " '반복': 831,\n",
       " '않음': 832,\n",
       " 'ㅋㅋㅋ': 833,\n",
       " '아니면': 834,\n",
       " '사': 835,\n",
       " '에서도': 836,\n",
       " '아마': 837,\n",
       " '챕': 838,\n",
       " '당': 839,\n",
       " '막': 840,\n",
       " '들어서': 841,\n",
       " '내시': 842,\n",
       " '모르겠습니다': 843,\n",
       " '이라도': 844,\n",
       " '얻어가는': 845,\n",
       " '확인': 846,\n",
       " '서평': 847,\n",
       " '에만': 848,\n",
       " '은근': 849,\n",
       " '이용': 850,\n",
       " '로는': 851,\n",
       " '남는': 852,\n",
       " '.(': 853,\n",
       " '바로': 854,\n",
       " '휴강': 855,\n",
       " '노트': 856,\n",
       " '오히려': 857,\n",
       " '않아': 858,\n",
       " '받는': 859,\n",
       " '추가': 860,\n",
       " '이과': 861,\n",
       " '예': 862,\n",
       " '빨리': 863,\n",
       " '적은': 864,\n",
       " '좋으세요': 865,\n",
       " '저희': 866,\n",
       " '물': 867,\n",
       " '신청': 868,\n",
       " '족보': 869,\n",
       " '하신다': 870,\n",
       " '텍스트': 871,\n",
       " '어려워서': 872,\n",
       " '어려워요': 873,\n",
       " '하기가': 874,\n",
       " '외워서': 875,\n",
       " '많다': 876,\n",
       " '로만': 877,\n",
       " '빈칸': 878,\n",
       " '많은데': 879,\n",
       " '나쁘지': 880,\n",
       " '않아도': 881,\n",
       " '장점': 882,\n",
       " 'F': 883,\n",
       " '야합니다': 884,\n",
       " '초': 885,\n",
       " '간': 886,\n",
       " '따라서': 887,\n",
       " '새로운': 888,\n",
       " '페이퍼': 889,\n",
       " '국제': 890,\n",
       " '쓰시': 891,\n",
       " '후반': 892,\n",
       " '이건': 893,\n",
       " '많았습니다': 894,\n",
       " '.)': 895,\n",
       " '이전': 896,\n",
       " '받고': 897,\n",
       " '어렵진': 898,\n",
       " '결국': 899,\n",
       " '부': 900,\n",
       " '용도': 901,\n",
       " '그게': 902,\n",
       " '외워야': 903,\n",
       " '일본어': 904,\n",
       " '한다는': 905,\n",
       " '유익한': 906,\n",
       " '현': 907,\n",
       " '이유': 908,\n",
       " '였는데': 909,\n",
       " '한글': 910,\n",
       " '각각': 911,\n",
       " '.....': 912,\n",
       " '모르겠지만': 913,\n",
       " '감상문': 914,\n",
       " '논리': 915,\n",
       " '하셨는데': 916,\n",
       " '않을': 917,\n",
       " '그때': 918,\n",
       " '평이': 919,\n",
       " '그렇지만': 920,\n",
       " '유형': 921,\n",
       " '보': 922,\n",
       " '100': 923,\n",
       " '기분': 924,\n",
       " '봐서': 925,\n",
       " '중국': 926,\n",
       " '모습': 927,\n",
       " '!!!': 928,\n",
       " '외국인': 929,\n",
       " '활동': 930,\n",
       " '일찍': 931,\n",
       " '푸는': 932,\n",
       " '였어요': 933,\n",
       " '변별': 934,\n",
       " 'the': 935,\n",
       " '가서': 936,\n",
       " '계획': 937,\n",
       " '노트북': 938,\n",
       " '교육': 939,\n",
       " '등등': 940,\n",
       " '쉽지': 941,\n",
       " '타': 942,\n",
       " '이며': 943,\n",
       " '딴': 944,\n",
       " '그걸': 945,\n",
       " '되기': 946,\n",
       " '비쁠': 947,\n",
       " '리포트': 948,\n",
       " '학과': 949,\n",
       " '애': 950,\n",
       " '따라갈': 951,\n",
       " '표현': 952,\n",
       " '강의실': 953,\n",
       " '배워': 954,\n",
       " '실수': 955,\n",
       " '독학': 956,\n",
       " '들으면서': 957,\n",
       " '필요한': 958,\n",
       " '짱': 959,\n",
       " '감점': 960,\n",
       " '문장': 961,\n",
       " '고생': 962,\n",
       " '자유': 963,\n",
       " '보지': 964,\n",
       " '적극': 965,\n",
       " '있으신': 966,\n",
       " '학교': 967,\n",
       " '주신다': 968,\n",
       " '하신다면': 969,\n",
       " '적고': 970,\n",
       " '자세히': 971,\n",
       " '서도': 972,\n",
       " '이면': 973,\n",
       " '예요': 974,\n",
       " '중국어': 975,\n",
       " '회계': 976,\n",
       " ',,': 977,\n",
       " '최악': 978,\n",
       " '상대평가': 979,\n",
       " '응용': 980,\n",
       " '예시': 981,\n",
       " '심리학': 982,\n",
       " '성격': 983,\n",
       " '대체로': 984,\n",
       " '인가': 985,\n",
       " '제시': 986,\n",
       " '써': 987,\n",
       " '있다는': 988,\n",
       " '사진': 989,\n",
       " '적용': 990,\n",
       " '대비': 991,\n",
       " '풀이': 992,\n",
       " '되요': 993,\n",
       " 'C': 994,\n",
       " '예습': 995,\n",
       " '재밌는': 996,\n",
       " '어렵지만': 997,\n",
       " '이신': 998,\n",
       " '굳이': 999,\n",
       " '꾸준히': 1000,\n",
       " '있다고': 1001,\n",
       " '이었고': 1002,\n",
       " '해당': 1003,\n",
       " ...}"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2word = {v:k for k, v in word2idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<UNUSED>'"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx2word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'내려갑니다'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx2word[9996]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.font_manager as fm\n",
    "import matplotlib.pyplot as plt\n",
    "from future.utils import iteritems\n",
    "from collections import Counter\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import urllib.request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dfx['Comment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2idx = {word.encode('utf8').decode('utf8'): ii for ii, word in enumerate(vocab,1)}\n",
    "word2idx = {k:v+3 for k, v in word2idx.items()}\n",
    "word2idx['<PAD>'] = 0\n",
    "word2idx['<START>'] = 1\n",
    "word2idx['<UNK>'] = 2\n",
    "word2idx['<UNUSED>'] = 3\n",
    "idx2word = {v:k for k, v in word2idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_idx2word = dict([(value, key) for (value, key) in idx2word.items()])\n",
    "\n",
    "def encode_review(text):\n",
    "    for key in word2idx:\n",
    "        return ' '.join([reverse_idx2word.get(i, key) for i in text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'. . . . . . . . . . . . . . . . . . . . . . . . . .'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encode_review(dfx['Comment'][0])\n",
    "#, values = ','.join(str(v) for v in value_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numbering_(row):\n",
    "    a = re.findall('\\'(.*?)\\'', str(row))\n",
    "    int_list = []\n",
    "    for morph in a:\n",
    "        if morph in word2idx:\n",
    "            int_ = word2idx[morph]\n",
    "            int_list.append(int_)\n",
    "            \n",
    "    return int_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfx['Comment'] = df.Comment.apply(lambda x: numbering_(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         [30, 85, 1206, 444, 15, 13938, 43, 6, 17412, 9...\n",
       "1         [1047, 12432, 6, 1329, 234, 116, 19, 7, 1445, ...\n",
       "2         [1206, 5, 296, 2954, 3882, 88, 149, 23, 7, 82,...\n",
       "3         [9023, 6339, 12, 11, 9, 1047, 949, 51, 21, 15,...\n",
       "4         [412, 15, 463, 792, 28, 21, 15, 412, 14, 81, 6...\n",
       "5         [322, 15, 136, 863, 6182, 59, 6, 2084, 15, 745...\n",
       "6         [667, 43, 6, 81, 467, 104, 37, 971, 289, 219, ...\n",
       "7            [20, 604, 3821, 10, 171, 60, 34, 1022, 320, 4]\n",
       "8         [995, 119, 5812, 14, 12, 11, 23, 2172, 1373, 1...\n",
       "9         [16, 9, 309, 239, 27, 10, 81, 51, 44, 2597, 72...\n",
       "10        [308, 143, 13, 739, 50, 234, 134, 20, 77, 1992...\n",
       "11        [285, 88, 1520, 7452, 129, 10, 1206, 10735, 42...\n",
       "12        [12, 11, 1009, 5, 87, 7, 441, 39, 145, 1339, 4...\n",
       "13        [3025, 52, 336, 410, 23, 21, 2102, 16, 29, 17,...\n",
       "14        [398, 29224, 522, 1206, 13, 4554, 2478, 89, 19...\n",
       "15        [8, 9, 20, 604, 121, 62, 10, 12, 11, 13, 983, ...\n",
       "16        [87, 761, 397, 20, 77, 1804, 126, 33, 7, 1409,...\n",
       "17        [49, 22, 264, 44, 6713, 10, 171, 13, 44, 897, ...\n",
       "18        [14256, 12, 11, 23, 4351, 21, 14, 46, 259, 68,...\n",
       "19        [1515, 757, 85, 2146, 84, 4, 1515, 305, 2253, ...\n",
       "20        [21, 15, 486, 217, 26581, 6, 2347, 12364, 178,...\n",
       "21        [1169, 20, 41, 126, 264, 106, 69, 16, 5, 14, 1...\n",
       "22                      [331, 379, 7239, 13, 840, 835, 512]\n",
       "23        [200, 15, 12, 11, 5, 1608, 2543, 108, 614, 81,...\n",
       "24        [4776, 627, 14, 12, 11, 5, 21, 117, 187, 5, 20...\n",
       "25            [222, 514, 47, 1077, 293, 244, 79, 7754, 257]\n",
       "26        [21, 138, 14, 1020, 19, 558, 393, 5, 100, 74, ...\n",
       "27        [21435, 1980, 379, 4, 4804, 915, 6, 14713, 250...\n",
       "28        [26582, 12, 11, 259, 4, 33, 5, 76, 12433, 7800...\n",
       "29        [1955, 32, 67, 420, 8, 35, 4, 120, 285, 767, 4...\n",
       "                                ...                        \n",
       "526124    [368, 6, 890, 752, 1041, 3321, 516, 6, 231, 5,...\n",
       "526125    [2499, 23, 410, 23, 1102, 102, 98, 656, 3047, ...\n",
       "526126    [656, 3047, 410, 23, 21, 261, 48, 45, 4, 2236,...\n",
       "526127    [6361, 7925, 136, 1646, 5826, 26, 70, 8, 35, 4...\n",
       "526128    [942, 52, 392, 143, 10, 4214, 336, 1322, 87, 5...\n",
       "526129    [15300, 153, 20, 1699, 4, 1080, 2476, 182, 108...\n",
       "526130    [46, 8, 7, 20, 132, 4, 954, 1034, 19, 540, 4, ...\n",
       "526131    [2563, 23, 19909, 24, 31, 7, 153, 20, 121, 14,...\n",
       "526132    [615, 6, 304, 207, 126, 5, 5, 8, 7, 279, 805, ...\n",
       "526133              [2612, 241, 277, 7, 788, 78, 8, 35, 68]\n",
       "526134    [6087, 2563, 64, 27, 396, 298, 4, 9219, 6, 719...\n",
       "526135    [569, 2821, 4292, 74, 44, 344, 26, 70, 21, 274...\n",
       "526136    [38, 73, 14, 230, 45, 4, 463, 8, 370, 109, 6, ...\n",
       "526137    [615, 334, 8, 179, 2563, 64, 34, 288, 223, 361...\n",
       "526138    [8, 5, 79, 663, 28, 64, 281, 79, 3284, 617, 4,...\n",
       "526139    [131, 982, 8, 7, 461, 32, 5, 1535, 649, 15, 53...\n",
       "526140    [395, 526, 22, 7, 2563, 64, 270, 43, 193, 6, 1...\n",
       "526141    [2471, 94, 1159, 12, 11, 8, 78, 16414, 175, 17...\n",
       "526142    [1071, 109, 2249, 1857, 2471, 94, 1159, 12, 11...\n",
       "526143    [21, 194, 1024, 638, 26, 70, 19, 5, 256, 277, ...\n",
       "526144    [81, 7, 44, 1706, 26, 70, 8, 10, 81, 7, 6468, ...\n",
       "526145    [11777, 728, 12, 11, 9, 69, 2371, 219, 12030, ...\n",
       "526146    [49, 22, 52, 500, 1293, 15, 20, 50, 858, 5072,...\n",
       "526147    [135, 9, 454, 24, 135, 11364, 768, 6227, 490, ...\n",
       "526148    [9225, 1183, 12, 15, 595, 24212, 529, 48, 141,...\n",
       "526149    [3640, 23, 20564, 10, 244, 339, 2779, 14, 353,...\n",
       "526150    [38, 73, 91, 1474, 2563, 47, 501, 16300, 78, 1...\n",
       "526151    [209, 4316, 69, 7, 69, 6052, 8, 6, 2165, 859, ...\n",
       "526152    [514, 13, 7011, 64, 6, 396, 298, 4, 46, 164, 1...\n",
       "526153    [8, 892, 24, 79, 5073, 257, 528, 1332, 90, 22,...\n",
       "Name: Comment, Length: 526154, dtype: object"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfx['Comment']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "max_words=5000\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(dfx['Comment'])\n",
    "dfx['Comment']=tokenizer.texts_to_sequences(dfx['Comment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Embedding, Dense, LSTM, GlobalAveragePooling1D, LeakyReLU, Dropout\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing import sequence\n",
    "from keras import optimizers\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(x_train[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dfx['Comment'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = dfx['Comment'][:410000]\n",
    "x_test = dfx['Comment'][410000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 150\n",
    "x_train = pad_sequences(x_train, value=word2idx['<PAD>'], padding='post', maxlen=max_len)\n",
    "x_test = pad_sequences(x_test, value=word2idx['<PAD>'], padding='post', maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  12,   11,   80,  103,  161,  221, 1113,   15,  574,  103,  583,\n",
       "        430,    7,  850,  430,   77,    7, 1735,    4,  105,    8,  102,\n",
       "        128,   14, 2748,    6, 8011,   15,  217, 3468,   59,    6,  460,\n",
       "          7,  824,  324,   32,   67,   25,    7,  226,   26,  378,    4,\n",
       "         16,    7,   20,  166,  129,   15,   20,  169,   31,    9,    7,\n",
       "         19,  250,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0])"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[19961]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "x_train=x_train/500\n",
    "x_test=x_test/500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = dfyyy[:410000]\n",
    "y_test = dfyyy[410000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray, numpy.ndarray, numpy.ndarray, numpy.float64)"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(x_train), type(x_train[16]), type(y_train), type(y_train[16126])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((410000, 150), (116154, 150), (410000,), (116154,))"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, x_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[6016].ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(max_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_38 (Embedding)     (None, 150, 256)          12800000  \n",
      "_________________________________________________________________\n",
      "dense_83 (Dense)             (None, 150, 512)          131584    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_32  (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_84 (Dense)             (None, 16)                8208      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_31 (LeakyReLU)   (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_85 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 12,939,809\n",
      "Trainable params: 12,939,809\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "max_words=50000\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_words, 256, input_length=150))\n",
    "model.add(Dense(512))\n",
    "model.add(GlobalAveragePooling1D())\n",
    "model.add(Dense(16))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(Dense(1))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, 150, 1)"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray, numpy.ndarray)"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(x_train), type(x_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 328000 samples, validate on 82000 samples\n",
      "Epoch 1/2\n",
      "   540/328000 [..............................] - ETA: 1:31:40 - loss: nan - acc: 0.0000e+00"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-351-ea35eb2637e6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'rmsprop'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'mse'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1439\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1440\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "Adam = optimizers.Adam\n",
    "#SGD = optimizers.SGD\n",
    "model.learning_rate=0.01\n",
    "model.compile(optimizer = 'rmsprop', loss='mse', metrics=['accuracy'])\n",
    "history = model.fit(x_train, y_train, epochs=2, batch_size=30, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116154/116154 [==============================] - 28s 238us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[nan, 0.0]"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "2.38",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-170-23110b8ccb48>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtestID\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1515\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m' '\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx2word\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mx_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtestID\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtestID\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtestID\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-170-23110b8ccb48>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtestID\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1515\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m' '\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx2word\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mx_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtestID\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtestID\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtestID\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 2.38"
     ]
    }
   ],
   "source": [
    "testID=1515\n",
    "print(' '.join([idx2word[idx] for idx in x_test[testID]]))\n",
    "out = model.predict(x_test[testID].reshape(1,-1))\n",
    "print(y_test[testID])\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이것도 평가해 보시지\n",
      "이 강의 세상에서 제일 개쓰레기에요 절대 듣지 마세요\n"
     ]
    }
   ],
   "source": [
    "comment=input(\"이것도 평가해 보시지\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'이 강의 세상에서 제일 개쓰레기에요 절대 듣지 마세요'"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0]])"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences=comment\n",
    "word_index=word2idx\n",
    "x_test=[[word_index[w] for w in sentences if w in word_index]]\n",
    "x_test = pad_sequences(x_test, maxlen=max_len)\n",
    "vector = np.array([x_test.flatten()])\n",
    "model.predict_classes(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
